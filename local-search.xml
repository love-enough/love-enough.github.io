<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MySQL八股文</title>
    <link href="/2024/07/05/MySQL%E5%85%AB%E8%82%A1%E6%96%87/"/>
    <url>/2024/07/05/MySQL%E5%85%AB%E8%82%A1%E6%96%87/</url>
    
    <content type="html"><![CDATA[<h2 id="一条SQL查询语句是如何执行的？"><a href="#一条SQL查询语句是如何执行的？" class="headerlink" title="一条SQL查询语句是如何执行的？"></a>一条SQL查询语句是如何执行的？</h2><ul><li>连接器：连接器负责和客户端建立连接，获取用户权限，维持和管理连接</li><li>查询缓存：MySQL拿到一条查询语句后，会先到缓存中查询之前是不是执行过此语句，之前执行的语句及其结果可能会以Key-value对的形式存储在缓存中，如果存在，直接返回结果。</li><li>分析器：输入的SQL语句是由字符串和空格构成的，MySQL需要识别出这些字符串分别是什么，代表什么。</li><li>优化器：当一个表存在多个索引时，优化器会决定使用哪个索引。或者一个语句中由多个表相连时，决定各个表的连接顺序。</li><li>执行器：通过分析和优化，知道了要做什么，并且还知道可该怎么做。接着就是进行语句的执行。</li></ul><h2 id="事务隔离级别有哪些？"><a href="#事务隔离级别有哪些？" class="headerlink" title="事务隔离级别有哪些？"></a>事务隔离级别有哪些？</h2><ul><li>读未提交：一个事务还没提交时，它的变更就能被其他事务看到。(会发生脏读、不可重复读、幻读)</li><li>读提交：一个事务提交后，他的变更才能被其他事务看到。(会发生不可重复读、幻读)</li><li>可重复读：一个事务在执行过程中看到的数据，总是跟在执行过程中看到的数据是一致的。(会发生幻读)</li><li>串行化：写会加写锁，读会加读锁。当出现读写锁冲突时，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><p>按隔离水平高低排序：</p><p>串行化 &gt; 可重复读 &gt; 读已提交 &gt; 读未提交</p><h2 id="这四种隔离级别是如何实现的呢？"><a href="#这四种隔离级别是如何实现的呢？" class="headerlink" title="这四种隔离级别是如何实现的呢？"></a>这四种隔离级别是如何实现的呢？</h2><ul><li>对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以&#x3D;&#x3D;直接读取最新的数据&#x3D;&#x3D;就好了；</li><li>对于「串行化」隔离级别的事务来说，通过&#x3D;&#x3D;加读写锁的方式来避免并行访问&#x3D;&#x3D;；</li><li>对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同。可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。</li></ul><h2 id="事务的四大特性是什么？"><a href="#事务的四大特性是什么？" class="headerlink" title="事务的四大特性是什么？"></a>事务的四大特性是什么？</h2><ul><li>原子性：事务时不可分割的最小工作单元，一个事务对应于一个完整的业务，一个事务的操作要么全部完成，要么全部没完成，当操作过程中出现问题，会回滚到原始状态。</li><li>一致性：事务执行之前和执行之后都必须处于一致性状态。</li><li>隔离性：允许多个并发的事务同时对数据进行修改和读取，执行互不干扰，防止多个事务并发执行由于交叉执行造成数据不一致的情况。</li><li>持久性：一个事务一旦被提交，那么对数据库中的数据的改变就是永久性的，即便在数据库系统中遇到故障的情况下也不会丢失提交事务的操作。</li></ul><h2 id="InnoDB引擎通过什么技术保证事务的四大特性呢？"><a href="#InnoDB引擎通过什么技术保证事务的四大特性呢？" class="headerlink" title="InnoDB引擎通过什么技术保证事务的四大特性呢？"></a>InnoDB引擎通过什么技术保证事务的四大特性呢？</h2><ul><li>持久性是通过 redo log （重做日志）来保证的；</li><li>原子性是通过 undo log（回滚日志） 来保证的；</li><li>隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；</li><li>一致性则是通过持久性+原子性+隔离性来保证；</li></ul><h2 id="并行事务会引发什么问题？"><a href="#并行事务会引发什么问题？" class="headerlink" title="并行事务会引发什么问题？"></a>并行事务会引发什么问题？</h2><p>在同时处理多个事务时，就可能出现&#x3D;&#x3D;脏读、不可重复读以及幻读&#x3D;&#x3D;。</p><ul><li>脏读：一个事务「读到」了另一个事务「未提交事务修改过的数据」。</li><li>不可重复读：在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。</li><li>幻读：在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。</li></ul><p>按严重性排序：</p><p>脏读 &gt; 不可重复读 &gt; 幻读</p><h2 id="MySQL可重复读隔离级别，完全解决幻读了吗？"><a href="#MySQL可重复读隔离级别，完全解决幻读了吗？" class="headerlink" title="MySQL可重复读隔离级别，完全解决幻读了吗？"></a>MySQL可重复读隔离级别，完全解决幻读了吗？</h2><ul><li>针对<strong>快照读</strong>（普通 select 语句），是<strong>通过 MVCC 方式解决了幻读</strong>，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。</li><li>针对<strong>当前读</strong>，是<strong>通过 next-key lock（记录锁+间隙锁）方式解决了幻读</strong>，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。</li></ul><h2 id="请举例可重复读隔离级别下，发生幻读的场景"><a href="#请举例可重复读隔离级别下，发生幻读的场景" class="headerlink" title="请举例可重复读隔离级别下，发生幻读的场景"></a>请举例可重复读隔离级别下，发生幻读的场景</h2><ul><li>对于快照读，MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。</li><li>对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。</li></ul><p><strong>可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读</strong>。</p><h2 id="如何避免可重复读隔离级别下发生幻读的场景呢？"><a href="#如何避免可重复读隔离级别下发生幻读的场景呢？" class="headerlink" title="如何避免可重复读隔离级别下发生幻读的场景呢？"></a>如何避免可重复读隔离级别下发生幻读的场景呢？</h2><ul><li>尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。</li></ul><h2 id="索引有哪些种类？"><a href="#索引有哪些种类？" class="headerlink" title="索引有哪些种类？"></a>索引有哪些种类？</h2><ul><li>从数据结构维度分类：<ul><li>B+树索引：所有子节点存储数据，适合范围查询。</li><li>哈希索引：适合等值查询。</li><li>全文索引：MyISAM和InnoDB中支持使用全文索引。</li><li>R-Tree索引：用来对GIS数据类型创建SPATIAL索引。</li></ul></li><li>从物理存储维度分类：<ul><li>（聚集索引）聚簇索引：数据存储与索引一起存放，叶子节点会存储一整行记录，找到索引也就找到了数据。</li><li>（非聚集）二级索引：数据存储与索引分开存放，叶子节点不存储数据，存储的是数据地址。</li></ul></li><li>从逻辑维度分类<ul><li>主键索引：一种特殊的唯一索引，不允许由空值。</li><li>唯一索引：索引列中的值必须唯一，值允许为空。</li><li>普通索引：MySQL中的基本索引类型，允许空值和重复值。</li><li>联合索引：多个字段创建的索引，使用时遵循最左前缀原则。</li><li>空间索引：MySQL5.7之后支持空间索引，在空间索引这方面遵循OpenGIS几何数据模型规则。</li></ul></li></ul><h2 id="MySQL为什么使用B-树来作索引呢？"><a href="#MySQL为什么使用B-树来作索引呢？" class="headerlink" title="MySQL为什么使用B+树来作索引呢？"></a>MySQL为什么使用B+树来作索引呢？</h2><ul><li>查询底层节点：B+树的非叶子节点不存放实际的记录数据，进存放索引，因此数据量相同的情况下，相比既存储索引又存储记录的B树，B+树可以有更大的空间来存放更多的索引，所以查询底层节点的磁盘I&#x2F;O次数会更少。</li><li>插入和删除：B+树有大量的冗余节点，删除一个节点时，可以直接从叶子节点中删除，甚至不用移动非叶子节点，删除非常块。插入也是一样，虽然插入可能存在节点的分裂（如果节点饱和），但是最多只涉及树的一条路径。B树没有冗余节点，删除的时候非常复杂，可能设计复杂的树的变形。</li><li>范围查询：B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I&#x2F;O 操作，范围查询效率不如 B+ 树。</li></ul><h2 id="B-树和B树的差异有哪些？"><a href="#B-树和B树的差异有哪些？" class="headerlink" title="B+树和B树的差异有哪些？"></a>B+树和B树的差异有哪些？</h2><ul><li>B+树的叶子节点存放实际数据（索引+记录），非叶子节点只会存放索引。</li><li>所有的索引都会在叶子节点出现，叶子节点之间构成一个有序链表。</li><li>非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。</li><li>非叶子节点中有多少个子节点，就有多少个索引；</li></ul><h2 id="什么时候需要建立索引？"><a href="#什么时候需要建立索引？" class="headerlink" title="什么时候需要建立索引？"></a>什么时候需要建立索引？</h2><ul><li><p>表的主关键字：自动建立唯一索引。</p></li><li><p>直接条件查询的字段：&#x3D;&#x3D;经常&#x3D;&#x3D;用于WHERE查询条件的字段，这样能够提高整个表的查询速度。</p></li><li><p>查询中与其它表关联的字段：例如字段建⽴了外键关系。</p></li><li><p>查询中排序的字段：排序的字段如果通过索引去访问将⼤⼤提⾼排序速度，否则用的是文件排序。</p></li><li><p>唯⼀性约束列： 如果某列具有唯⼀性约束，那么为了确保数据的唯⼀性，可以在这些列上创建唯</p><p>⼀索引。</p></li><li><p>⼤表中的关键列： 在⼤表中，如果查询的效率变得很低，可以考虑在关键列上创建索引。</p></li></ul><h2 id="什么时候不需要创建索引？"><a href="#什么时候不需要创建索引？" class="headerlink" title="什么时候不需要创建索引？"></a>什么时候不需要创建索引？</h2><ul><li><p>小表：对⼩表创建索引可能会带来额外的开销，因为在⼩数据集中扫描整个表可能⽐使⽤索引更</p><p>快。</p></li><li><p>频繁的插入、更新和删除：索引的维护成本会随着数据的插⼊、更新和删除操作⽽增加。如</p><p>果表经常被修改，过多的索引可能会影响性能。</p></li><li><p>数据重复且均匀分布：这种字段建索引⼀般不会提⾼数据库的查询速度。</p></li><li><p>很少被查询的列：如果某列很少被⽤于查询条件，那么为它创建索引可能没有明显的性能提</p><p>升。</p></li><li><p>查询结果总行数很少的列：如果查询的结果集总⾏数很少，使⽤索引可能不会有太⼤的性能提</p><p>升。</p></li></ul><h2 id="索引失效的场景有哪些？"><a href="#索引失效的场景有哪些？" class="headerlink" title="索引失效的场景有哪些？"></a>索引失效的场景有哪些？</h2><ul><li><p>当我们使用左或者左右模糊匹配的时候，也就是 <code>like %xx</code> 或者 <code>like %xx%</code>这两种方式都会造成索引失效；</p></li><li><p>表连接中的列类型不匹配： 如果在连接操作中涉及的两个表的列类型不匹配，索引可能会失效。</p><p>例如，⼀个表的列是整数，另⼀个表的列是字符，连接时可能会导致索引失效。</p></li><li><p>当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；</p></li><li><p>不等号条件： 当查询中包含不等号条件（如&gt;,&lt;,&gt;&#x3D;,&lt;&#x3D;）时，索引可能会失效。通常情况下，索</p><p>引只能⽤于等值⽐较。</p></li><li><p>OR 条件： 当查询中使⽤多个 OR 条件时，如果这些条件不涉及同⼀列，索引可能⽆法有效使</p><p>⽤。数据库可能会选择全表扫描⽽不是使⽤多个索引。</p></li></ul><h2 id="优化索引的方法有哪些？"><a href="#优化索引的方法有哪些？" class="headerlink" title="优化索引的方法有哪些？"></a>优化索引的方法有哪些？</h2><ul><li>前缀索引优化</li><li>覆盖索引优化</li><li>主键索引最好是自增的</li><li>防止索引失效</li></ul><h2 id="MySQL的执行引擎有哪些？"><a href="#MySQL的执行引擎有哪些？" class="headerlink" title="MySQL的执行引擎有哪些？"></a>MySQL的执行引擎有哪些？</h2><ul><li>InnoDB：引擎提供了对事务ACID的⽀持，还提供了⾏级锁和外键的约束。</li><li>MyISAM：引擎不⽀持事务，也不⽀持⾏级锁和外键约束。</li><li>Memery：就是将数据放在内存中，数据处理速度很快，但是安全性不⾼。</li></ul><h2 id="MySQL单表不要超过2000w行，靠谱吗？"><a href="#MySQL单表不要超过2000w行，靠谱吗？" class="headerlink" title="MySQL单表不要超过2000w行，靠谱吗？"></a>MySQL单表不要超过2000w行，靠谱吗？</h2><p>2000w只是推荐值，超过这个值可能会导致B+树层级更高，影响查询性能。</p><h2 id="count-和count-1-有什么区别？哪个性能更好？"><a href="#count-和count-1-有什么区别？哪个性能更好？" class="headerlink" title="count(*)和count(1)有什么区别？哪个性能更好？"></a>count(*)和count(1)有什么区别？哪个性能更好？</h2><p>count(*)其实等于 count(0)，也就是说，当你使用 count(*) 时，MySQL 会将 * 参数转化为参数 0 来处理。</p><p><strong>性能排序</strong></p><p>&#x3D;&#x3D;count(*) &#x3D; count(1) &gt; count(主键字段) &gt; count(字段)&#x3D;&#x3D;</p><p>count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。</p><h2 id="如何优化count"><a href="#如何优化count" class="headerlink" title="如何优化count(*)?"></a>如何优化count(*)?</h2><ul><li>近似值：如果业务对于统计个数不需要很精确，可以使用show table status或者explain命令来进行估算。</li><li>额外表保存计数值：想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。</li></ul><h2 id="MySQL使用-like-“-x”，索引一定会失效吗？"><a href="#MySQL使用-like-“-x”，索引一定会失效吗？" class="headerlink" title="MySQL使用 like “%x”，索引一定会失效吗？"></a>MySQL使用 like “%x”，索引一定会失效吗？</h2><p><strong>不一定</strong></p><p>因为如果这张表的字段都是索引字段，那么查询的时候就会使用覆盖索引，<strong>查询的数据都在二级索引的 B+ 树，因为二级索引的 B+ 树的叶子节点包含「索引值+主键值」，所以查二级索引的 B+ 树就能查到全部结果了</strong></p><p>但是如果查询字段中含有非索引字段，那么索引就会失效了，要查询的数据就不能只在二级索引树里找了，得需要回表操作才能完成查询的工作，再加上是左模糊匹配，无法利用索引树的有序性来快速定位数据，所以得在二级索引树逐一遍历，获取主键值后，再到聚簇索引树检索到对应的数据行，优化器认为上面这样的查询过程的成本实在太高了，所以直接选择全表扫描的方式来查询数据。</p><h2 id="MySQL有哪些锁呢？"><a href="#MySQL有哪些锁呢？" class="headerlink" title="MySQL有哪些锁呢？"></a>MySQL有哪些锁呢？</h2><ul><li><p>全局锁：主要应用于做<strong>全库逻辑备份</strong>，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。</p><ul><li>全局锁有什么缺点呢？<ul><li>加上全局锁，意味着整个数据库都是只读状态。那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。</li></ul></li><li>使用全局锁会影响业务，那有什么其他方式可以避免？<ul><li>如果数据库的引擎支持的事务支持<strong>可重复读的隔离级别</strong>，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。</li></ul></li></ul></li><li><p>表级锁</p><ul><li><p>表锁：表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。</p></li><li><p>元数据锁：对数据库表进行操作时，会⾃动给这个表加上元数据锁，为了保证当⽤户对表执⾏ CRUD 操作时，其他线程对这个表结构做了变更。元数据锁在事务提交后才会释放。</p></li><li><p>意向锁：对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。</p><p>而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。</p><ul><li><strong>意向锁的目的是为了快速判断表里是否有记录被加锁</strong>。</li></ul></li><li><p>AUTO-INC锁：表⾥的主键通常都会设置成⾃增的，之后可以在插⼊数据时，可以不指定主键的值，数据库会⾃动给主键赋值递增的值通过 AUTO-INC 锁实现的。&#x3D;&#x3D;在插⼊数据时，会加⼀个表级别的 AUTO-INC 锁&#x3D;&#x3D;，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插⼊语句执⾏完成后，才会把 AUTO-INC 锁释放掉。其他事务的如果要向该表插⼊语句都会被阻塞，从⽽保证插⼊数据时字段的值是连续递增的。</p></li></ul></li><li><p>行级锁</p><ul><li>Record Lock：记录锁，也就是仅仅把一条记录锁上；记录锁分为排他锁和共享锁。<ul><li>只有S和S兼容</li><li>共享锁（S锁）满足读读共享，读写互斥。</li><li>独占锁（X锁）满足写写互斥、读写互斥。</li></ul></li><li>Gap Lock：间隙锁，锁定一个范围，但是不包含记录本身；只存在于可重复读隔离级别，⽬的是为了解决可重复读隔离级别下幻读的现象。<strong>间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系</strong></li><li>Next-Key Lock：&#x3D;&#x3D;Record Lock + Gap Lock 的组合&#x3D;&#x3D;，锁定一个范围，并且锁定记录本身。next-key lock 即能保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。</li><li>插入意向锁：⼀个事务在插⼊⼀条记录的时候，需要判断插⼊位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插⼊操作就会发⽣阻塞，直到拥有间隙锁的那个事务提交为止，在此期间会⽣成⼀个插⼊意向锁，表明有事务想在某个区间插⼊新记录，但是现在处于等待状态。</li></ul></li></ul><h2 id="update没加索引会锁全表？"><a href="#update没加索引会锁全表？" class="headerlink" title="update没加索引会锁全表？"></a>update没加索引会锁全表？</h2><p>是的，会引起锁全表！<strong>在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了</strong>。</p><p>-<br>  执行 update 语句的时候，确保 where 条件中带上了索引列，并且在测试机确认该语句是否走的是索引扫描，防止因为扫描全表，而对表中的所有记录加上锁。</p><ul><li>打开 MySQL sql_safe_updates 参数，这样可以预防 update 操作时 where 条件没有带上索引列。</li><li>如果发现即使在 where 条件中带上了列索引列，优化器走的还是全标扫描，这时我们就要使用 <code>force index([index_name])</code> 可以告诉优化器使用哪个索引。</li></ul><h2 id="MySQL记录锁-间隙锁可以防止删除操作而导致幻读吗？"><a href="#MySQL记录锁-间隙锁可以防止删除操作而导致幻读吗？" class="headerlink" title="MySQL记录锁+间隙锁可以防止删除操作而导致幻读吗？"></a>MySQL记录锁+间隙锁可以防止删除操作而导致幻读吗？</h2><p>可以防止此类事情发生！</p><ul><li>在 MySQL 的可重复读隔离级别下，针对当前读的语句会对<strong>索引</strong>加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。</li><li>在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。</li></ul><h2 id="MySQL死锁了，怎么办？"><a href="#MySQL死锁了，怎么办？" class="headerlink" title="MySQL死锁了，怎么办？"></a>MySQL死锁了，怎么办？</h2><p>死锁的四个必要条件：<strong>互斥、占有且等待、不可强占用、循环等待</strong>。</p><p>两种策略通过打破循环等待条件来解除死锁状态：</p><ul><li>设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。</li><li>开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。</li></ul><h2 id="MySQL日志文件有哪几种？有什么用？"><a href="#MySQL日志文件有哪几种？有什么用？" class="headerlink" title="MySQL日志文件有哪几种？有什么用？"></a>MySQL日志文件有哪几种？有什么用？</h2><ul><li>undo log：回滚日志，是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。<ul><li>MVCC是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。</li></ul></li><li>redo log：重做日志，是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>。</li><li>binlog：归档日志，是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>。</li></ul>]]></content>
    
    
    <categories>
      
      <category>八股</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
      <tag>八股</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis八股文</title>
    <link href="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/"/>
    <url>/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是Redis？"><a href="#什么是Redis？" class="headerlink" title="什么是Redis？"></a>什么是Redis？</h2><p>Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此<strong>读写速度非常快</strong>，常用于<strong>缓存，消息队列、分布式锁等场景</strong>。Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是<strong>原子性</strong>的，因为执行命令由单线程负责的，不存在并发竞争的问题。</p><h2 id="Redis和Memcached有什么区别？"><a href="#Redis和Memcached有什么区别？" class="headerlink" title="Redis和Memcached有什么区别？"></a>Redis和Memcached有什么区别？</h2><ul><li>共同点<ul><li>都是基于内存的数据库，一般都用来当作缓存使用。</li><li>都有过期的策略。</li><li>两者的性能都非常高。</li></ul></li><li>区别：<ul><li>Redis支持的数据类型更为丰富，而Memcached只支持简单的key-value数据类型。</li><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li><li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li><li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</li></ul></li></ul><h2 id="为什么用Redis作为MySQL的缓存？"><a href="#为什么用Redis作为MySQL的缓存？" class="headerlink" title="为什么用Redis作为MySQL的缓存？"></a>为什么用Redis作为MySQL的缓存？</h2><ul><li>Redis具有高性能。用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。</li><li>Redis具有高并发。直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</li></ul><h2 id="Redis的数据类型以及使用场景是什么？"><a href="#Redis的数据类型以及使用场景是什么？" class="headerlink" title="Redis的数据类型以及使用场景是什么？"></a>Redis的数据类型以及使用场景是什么？</h2><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-17201898400001.png" alt="五种数据类型"></p><ul><li>String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。</li><li>List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。</li><li>Hash 类型：缓存对象、购物车等。</li><li>Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。</li><li>Zset 类型：排序场景，比如排行榜、电话和姓名排序等。</li></ul><h2 id="五种常见的Redis数据类型是怎么实现的？"><a href="#五种常见的Redis数据类型是怎么实现的？" class="headerlink" title="五种常见的Redis数据类型是怎么实现的？"></a>五种常见的Redis数据类型是怎么实现的？</h2><ul><li>String类型的内部实现<ul><li>SDS 不仅可以保存文本数据，还可以保存二进制数据。</li><li>SDS 获取字符串长度的时间复杂度是 O(1)。</li><li>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。</li></ul></li><li>List类型内部实现<ul><li>List 数据类型底层数据结构由 quicklist 实现了，替代了双向链表和压缩列表。</li></ul></li><li>Hash 类型内部实现<ul><li>如果哈希类型元素个数小于 512 个，所有值小于 64 字节的话，Redis 会使用<strong>压缩列表</strong>作为 Hash 类型的底层数据结构；<strong>压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了</strong>。</li><li>如果哈希类型元素不满足上面条件，Redis 会使用<strong>哈希表</strong>作为 Hash 类型的底层数据结构。</li></ul></li><li>Set 类型内部实现<ul><li>如果集合中的元素都是整数且元素个数小于 512 个，Redis 会使用<strong>整数集合</strong>作为 Set 类型的底层数据结构；</li><li>如果集合中的元素不满足上面条件，则 Redis 使用<strong>哈希表</strong>作为 Set 类型的底层数据结构。</li></ul></li><li>ZSet 类型内部实现<ul><li>如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用<strong>压缩列表</strong>作为 Zset 类型的底层数据结构；<strong>压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</strong></li><li>如果有序集合的元素不满足上面的条件，Redis 会使用<strong>跳表</strong>作为 Zset 类型的底层数据结构；</li></ul></li></ul><h2 id="Redis是单线程吗？"><a href="#Redis是单线程吗？" class="headerlink" title="Redis是单线程吗？"></a>Redis是单线程吗？</h2><ul><li>Redis 单线程指的是<strong>「接收客户端请求-&gt;解析请求 -&gt;进行数据读写等操作-&gt;发送数据给客户端」</strong>这个过程是由一个线程（主线程）来完成的。</li><li>但是，<strong>Redis 程序并不是单线程的</strong>，Redis 在启动的时候，是会<strong>启动后台线程</strong>的，2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；1个新的后台线程，用来异步释放 Redis 内存。之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。</li></ul><h2 id="Redis采用单线程为什么还那么快？"><a href="#Redis采用单线程为什么还那么快？" class="headerlink" title="Redis采用单线程为什么还那么快？"></a>Redis采用单线程为什么还那么快？</h2><ul><li>Redis 的大部分操作<strong>都在内存中完成</strong>，并且采用了高效的数据结构。因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；</li><li>Redis 采用单线程模型可以<strong>避免了多线程之间的竞争</strong>，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。</li><li>Redis 采用了 <strong>I&#x2F;O 多路复用机制</strong>处理大量的客户端 Socket 请求，简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。</li></ul><h2 id="Redis-6-0之前为什么使用单线程？"><a href="#Redis-6-0之前为什么使用单线程？" class="headerlink" title="Redis 6.0之前为什么使用单线程？"></a>Redis 6.0之前为什么使用单线程？</h2><ul><li><strong>CPU 并不是制约 Redis 性能表现的瓶颈所在</strong>，更多情况下是受到内存大小和网络I&#x2F;O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题</li><li>使用了单线程后，可维护性高，多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，<strong>增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗</strong>。</li></ul><h2 id="Redis-6-0之后为什么引入了多线程？"><a href="#Redis-6-0之后为什么引入了多线程？" class="headerlink" title="Redis 6.0之后为什么引入了多线程？"></a>Redis 6.0之后为什么引入了多线程？</h2><ul><li>在 Redis 6.0 版本之后，也<strong>采用了多个 I&#x2F;O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上。</strong>但是对于命令的执行，Redis 仍然使用单线程来处理**</li></ul><p> Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会<strong>额外创建 6 个线程</strong></p><ul><li>Redis-server ： Redis的主线程，主要负责执行命令；</li><li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li><li>io_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，I&#x2F;O 多线程，用来分担 Redis 网络 I&#x2F;O 的压力。</li></ul><h2 id="Redis如何实现数据不丢失？"><a href="#Redis如何实现数据不丢失？" class="headerlink" title="Redis如何实现数据不丢失？"></a>Redis如何实现数据不丢失？</h2><p>为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。</p><p>三种数据持久化的方式：</p><ul><li><strong>AOF 日志</strong>：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；</li><li><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘；</li><li><strong>混合持久化方式</strong>：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；</li></ul><h2 id="AOF日志是如何实现的？"><a href="#AOF日志是如何实现的？" class="headerlink" title="AOF日志是如何实现的？"></a>AOF日志是如何实现的？</h2><p>Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。</p><h2 id="为什么先执行命令，再把数据写入日志呢？"><a href="#为什么先执行命令，再把数据写入日志呢？" class="headerlink" title="为什么先执行命令，再把数据写入日志呢？"></a>为什么先执行命令，再把数据写入日志呢？</h2><ul><li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li><li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li></ul><h2 id="AOF-写回策略有几种？"><a href="#AOF-写回策略有几种？" class="headerlink" title="AOF 写回策略有几种？"></a>AOF 写回策略有几种？</h2><ul><li><strong>Always</strong>，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li><li><strong>Everysec</strong>，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li><li><strong>No</strong>，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</li></ul><h2 id="AOF-日志过大，会触发什么机制"><a href="#AOF-日志过大，会触发什么机制" class="headerlink" title="AOF 日志过大，会触发什么机制?"></a>AOF 日志过大，会触发什么机制?</h2><p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。 如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。</p><p>AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。</p><h2 id="AOF重写期间，主进程修改了已存在的key-value对，出现的这种数据不一致问题如何解决？"><a href="#AOF重写期间，主进程修改了已存在的key-value对，出现的这种数据不一致问题如何解决？" class="headerlink" title="AOF重写期间，主进程修改了已存在的key-value对，出现的这种数据不一致问题如何解决？"></a>AOF重写期间，主进程修改了已存在的key-value对，出现的这种数据不一致问题如何解决？</h2><p>Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。</p><p>在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p><p>当子进程完成 AOF 重写工作后，会向主进程发送一条信号，主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p><ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li><li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li></ul><h2 id="RDB快照是如何实现的呢？"><a href="#RDB快照是如何实现的呢？" class="headerlink" title="RDB快照是如何实现的呢？"></a>RDB快照是如何实现的呢？</h2><p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，而 AOF 文件记录的是命令操作的日志，而不是实际的数据。因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p><h2 id="RDB做快照时会阻塞线程吗？"><a href="#RDB做快照时会阻塞线程吗？" class="headerlink" title="RDB做快照时会阻塞线程吗？"></a>RDB做快照时会阻塞线程吗？</h2><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行</p><ul><li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li><li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li></ul><h2 id="RDB在执行快照的时候，数据能修改吗？"><a href="#RDB在执行快照的时候，数据能修改吗？" class="headerlink" title="RDB在执行快照的时候，数据能修改吗？"></a>RDB在执行快照的时候，数据能修改吗？</h2><p>可以的，执行 bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于<strong>写时复制技术（Copy-On-Write, COW）。</strong>执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。</p><h2 id="为什么会有混合持久化？"><a href="#为什么会有混合持久化？" class="headerlink" title="为什么会有混合持久化？"></a>为什么会有混合持久化？</h2><ul><li>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。AOF 优点是丢失数据少，但是数据恢复不快。混合持久化既保证了 Redis 重启速度，又降低数据丢失风险。</li></ul><p>使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p><p><strong>优点</strong></p><ul><li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li></ul><p><strong>缺点</strong></p><ul><li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li><li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li></ul><h2 id="如何实现服务高可用？"><a href="#如何实现服务高可用？" class="headerlink" title="如何实现服务高可用？"></a>如何实现服务高可用？</h2><p>要想设计一个高可用的 Redis 服务，一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。</p><h2 id="解释一下脑裂现象，如何解决有其导致的数据丢失问题呢？"><a href="#解释一下脑裂现象，如何解决有其导致的数据丢失问题呢？" class="headerlink" title="解释一下脑裂现象，如何解决有其导致的数据丢失问题呢？"></a>解释一下脑裂现象，如何解决有其导致的数据丢失问题呢？</h2><p>由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p><p>解决方案：当主节点发现从节点连接的总数量小于阈值或者通信超时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p><h2 id="过期删除策略有哪些？"><a href="#过期删除策略有哪些？" class="headerlink" title="过期删除策略有哪些？"></a>过期删除策略有哪些？</h2><ul><li>定时删除：<strong>在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。</strong><ul><li>优点<ul><li>可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。</li></ul></li><li>缺点<ul><li>在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。</li></ul></li></ul></li><li>惰性删除：<strong>不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。</strong><ul><li>优点<ul><li>因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。</li></ul></li><li>缺点<ul><li>如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。</li></ul></li></ul></li><li>定期删除：<strong>每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。</strong><ul><li>优点<ul><li>通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li></ul></li><li>缺点<ul><li>内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。</li><li>难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。</li></ul></li></ul></li></ul><h2 id="Redis使用的过期删除策略是什么？"><a href="#Redis使用的过期删除策略是什么？" class="headerlink" title="Redis使用的过期删除策略是什么？"></a>Redis使用的过期删除策略是什么？</h2><p>Redis 使用的过期删除策略是「<strong>惰性删除+定期删除</strong>」这两种策略配和使用。以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。</p><h2 id="Redis如何实现惰性删除的？"><a href="#Redis如何实现惰性删除的？" class="headerlink" title="Redis如何实现惰性删除的？"></a>Redis如何实现惰性删除的？</h2><ul><li>Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期</li><li>如果过期，则删除该 key，然后返回 null 客户端；</li><li>如果没有过期，不做任何处理，然后返回正常的键值对给客户端；</li></ul><h2 id="Redis如何实现定期删除的？"><a href="#Redis如何实现定期删除的？" class="headerlink" title="Redis如何实现定期删除的？"></a>Redis如何实现定期删除的？</h2><ul><li>从过期字典中随机抽取 20 个 key；</li><li>检查这 20 个 key 是否过期，并删除已过期的 key；</li><li>如果本轮检查的已过期 key 的数量，超过 5 个（20&#x2F;4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li></ul><p>Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</p><h2 id="Redis持久化时，对过期键会如何处理？"><a href="#Redis持久化时，对过期键会如何处理？" class="headerlink" title="Redis持久化时，对过期键会如何处理？"></a>Redis持久化时，对过期键会如何处理？</h2><p>对于RDB文件来说，分为生成阶段和加载阶段</p><ul><li><strong>RDB 文件生成阶段</strong>：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，<strong>过期的键「不会」被保存到新的 RDB 文件中</strong>，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响。</li><li><strong>RDB 加载阶段</strong><ul><li><strong>如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中</strong>。</li><li><strong>如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中</strong>。但由于主从服务器在进行数据同步时，从服务器的数据会被清空。</li></ul></li></ul><p>对于AOF 文件来说，分为两个阶段：AOF 文件写入阶段和 AOF 重写阶段。</p><ul><li><strong>AOF 文件写入阶段</strong>：当 Redis 以 AOF 模式持久化时，<strong>如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值</strong>。</li><li><strong>AOF 重写阶段</strong>：执行 AOF 重写时，会对 Redis 中的键值对进行检查，<strong>已过期的键不会被保存到重写后的 AOF 文件中</strong>，因此不会对 AOF 重写造成任何影响。</li></ul><h2 id="Redis主从模式中，会对过期键如何处理？"><a href="#Redis主从模式中，会对过期键如何处理？" class="headerlink" title="Redis主从模式中，会对过期键如何处理？"></a>Redis主从模式中，会对过期键如何处理？</h2><p><strong>从库不会进行过期扫描，从库对过期的处理是被动的</strong>。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。从库的过期键处理依靠主服务器控制，<strong>主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库</strong>，从库通过执行这条 del 指令来删除过期的 key。</p><h2 id="Redis内存满了，会发生什么？"><a href="#Redis内存满了，会发生什么？" class="headerlink" title="Redis内存满了，会发生什么？"></a>Redis内存满了，会发生什么？</h2><p>在 Redis 的运行内存达到了某个阀值，就会触发<strong>内存淘汰机制</strong>，这个阀值就是我们设置的最大运行内存，</p><h2 id="Redis内存淘汰策略有哪些？"><a href="#Redis内存淘汰策略有哪些？" class="headerlink" title="Redis内存淘汰策略有哪些？"></a>Redis内存淘汰策略有哪些？</h2><ul><li>不进行数据淘汰的策略<ul><li><strong>noeviction</strong>：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。</li></ul></li><li>进行数据淘汰的策略<ul><li>在设置了过期时间的数据中进行淘汰<ul><li><strong>volatile-random</strong>：随机淘汰设置了过期时间的任意键值；</li><li><strong>volatile-ttl</strong>：优先淘汰更早过期的键值。</li><li><strong>volatile-lru</strong>：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li><li><strong>volatile-lfu</strong>：淘汰所有设置了过期时间的键值中，最少使用的键值；</li></ul></li><li>在所有数据范围内进行淘汰<ul><li><strong>allkeys-random</strong>：随机淘汰任意键值;</li><li><strong>allkeys-lru</strong>：淘汰整个键值中最久未使用的键值；</li><li><strong>allkeys-lfu</strong>：淘汰整个键值中最少使用的键值。</li></ul></li></ul></li></ul><h2 id="Redis如何实现LRU算法？"><a href="#Redis如何实现LRU算法？" class="headerlink" title="Redis如何实现LRU算法？"></a>Redis如何实现LRU算法？</h2><p>Redis 实现的是一种<strong>近似 LRU 算法</strong>，目的是为了更好的节约内存，它的<strong>实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间</strong>。</p><p>当 Redis 进行内存淘汰时，会使用<strong>随机采样的方式来淘汰数据</strong>，然后<strong>淘汰最久没有使用的那个</strong>。</p><p>Redis 实现的 LRU 算法的优点：</p><ul><li>不用为所有的数据维护一个大链表，节省了空间占用；</li><li>不用在每次数据访问时都移动链表项，提升了缓存的性能；</li></ul><p>缺点：<strong>无法解决缓存污染问题</strong>，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。</p><h2 id="Redis如何实现LFU算法？"><a href="#Redis如何实现LFU算法？" class="headerlink" title="Redis如何实现LFU算法？"></a>Redis如何实现LFU算法？</h2><p>LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息</p><p>LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。</p><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/061e2c04e0ebca3425dd75dd035b6b7b-172019020901413.png" alt="常见Redis缓存问题"></p><h2 id="如何避免缓存雪崩？"><a href="#如何避免缓存雪崩？" class="headerlink" title="如何避免缓存雪崩？"></a>如何避免缓存雪崩？</h2><p>当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是<strong>缓存雪崩</strong>的问题。</p><ul><li><strong>将缓存失效时间随机打散：</strong> 我们可以在原有的失效时间基础上增加一个随机值（比如 1 到 10 分钟）这样每个缓存的过期时间都不重复了，也就降低了缓存集体失效的概率。</li><li><strong>设置缓存不过期：</strong> 我们可以通过后台服务来更新缓存数据，从而避免因为缓存失效造成的缓存雪崩，也可以在一定程度上避免缓存并发问题。</li></ul><h2 id="如何避免缓存击穿？"><a href="#如何避免缓存击穿？" class="headerlink" title="如何避免缓存击穿？"></a>如何避免缓存击穿？</h2><p>如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是<strong>缓存击穿</strong>的问题。</p><ul><li>互斥锁方案：保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li><li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li></ul><h2 id="如何避免缓存穿透？"><a href="#如何避免缓存穿透？" class="headerlink" title="如何避免缓存穿透？"></a>如何避免缓存穿透？</h2><p>当用户访问的数据，<strong>既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是<strong>缓存穿透</strong>的问题。</p><ul><li><strong>非法请求的限制</strong>：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</li><li><strong>设置空值或者默认值</strong>：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</li><li><strong>使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在</strong>：我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在，即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</li></ul><h2 id="如何设计一个缓存策略，可以动态缓存热点数据呢？"><a href="#如何设计一个缓存策略，可以动态缓存热点数据呢？" class="headerlink" title="如何设计一个缓存策略，可以动态缓存热点数据呢？"></a>如何设计一个缓存策略，可以动态缓存热点数据呢？</h2><p>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong>。</p><h2 id="说说常见的缓存更新策略"><a href="#说说常见的缓存更新策略" class="headerlink" title="说说常见的缓存更新策略"></a>说说常见的缓存更新策略</h2><p>实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略应用不了。</p><ul><li><p>Cache Aside（旁路缓存）策略：应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。</p><ul><li>写策略：先更新数据库中的数据，再删除缓存中的数据。</li><li>读策略：如果读取的数据命中了缓存，则直接返回数据；如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。</li></ul><p>写策略的步骤的顺序不能倒过来，即<strong>不能先删除缓存再更新数据库</strong>，原因是在「读+写」并发的时候，会出现缓存和数据库的数据不一致性的问题。</p></li><li><p>Read Through 策略：先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。</p></li><li><p>Write Through 策略</p><ul><li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li><li>如果缓存中数据不存在，直接更新数据库，然后返回；</li></ul></li><li><p>Write Back（写回）策略：在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。</p></li></ul><h2 id="Redis如何实现延迟队列？"><a href="#Redis如何实现延迟队列？" class="headerlink" title="Redis如何实现延迟队列？"></a>Redis如何实现延迟队列？</h2><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。</p><ul><li>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。</li><li>使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。</li></ul><h2 id="Redis管道有什么用？"><a href="#Redis管道有什么用？" class="headerlink" title="Redis管道有什么用？"></a>Redis管道有什么用？</h2><p>管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。使用<strong>管道技术可以解决多个命令执行时的网络等待</strong>，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。</p><h2 id="Redis事务支持回滚吗？"><a href="#Redis事务支持回滚吗？" class="headerlink" title="Redis事务支持回滚吗？"></a>Redis事务支持回滚吗？</h2><p><strong>Redis 中并没有提供回滚机制</strong></p><h2 id="如何用Redis实现分布式锁？"><a href="#如何用Redis实现分布式锁？" class="headerlink" title="如何用Redis实现分布式锁？"></a>如何用Redis实现分布式锁？</h2><p>通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁。</p><p><strong>优点</strong></p><ul><li>性能高效</li><li>实现方便</li><li>避免单点故障</li></ul><p><strong>缺点</strong></p><ul><li><strong>超时时间不好设置</strong>。如果锁的超时时间设置过长，会影响性能，如果设置的超时时间过短会保护不到共享资源。<ul><li>解决方案：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可，不过这种方式实现起来相对复杂。</li></ul></li><li><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>。</li></ul><h2 id="Redis-大-Key-对持久化有什么影响？"><a href="#Redis-大-Key-对持久化有什么影响？" class="headerlink" title="Redis 大 Key 对持久化有什么影响？"></a>Redis 大 Key 对持久化有什么影响？</h2><ul><li>当 AOF 写回策略配置了 Always 策略，如果写入是一个大 Key，主线程在执行 fsync() 函数的时候，阻塞的时间会比较久，因为当写入的数据量很大的时候，数据同步到硬盘这个过程是很耗时的。</li><li>AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 <code>fork()</code> 函数创建一个子进程来处理任务。会有两个阶段会导致阻塞父进程（主线程）<ul><li>创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长；</li><li>创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存会很大，那么在复制物理内存这一过程，就会比较耗时，所以有可能会阻塞父进程。</li></ul></li></ul><h2 id="大-Key-还有哪些影响？"><a href="#大-Key-还有哪些影响？" class="headerlink" title="大 Key 还有哪些影响？"></a>大 Key 还有哪些影响？</h2><ul><li>客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li>引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li>阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li><li>内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li></ul><h2 id="如何避免大-Key？"><a href="#如何避免大-Key？" class="headerlink" title="如何避免大 Key？"></a>如何避免大 Key？</h2><p>最好在设计阶段，就把大 key 拆分成一个一个小 key。或者，定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令删除，因为该命令删除过程会阻塞主线程，而是用 unlink 命令删除大 key，因为该命令的删除过程是异步的，不会阻塞主线程。</p><h2 id="如何判断key已过期？"><a href="#如何判断key已过期？" class="headerlink" title="如何判断key已过期？"></a>如何判断key已过期？</h2><p>Redis 首先检查该 key 是否存在于过期字典中，如果不在，则正常读取键值；如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。</p><h2 id="Redis主从节点是长连接还是短链接？"><a href="#Redis主从节点是长连接还是短链接？" class="headerlink" title="Redis主从节点是长连接还是短链接？"></a>Redis主从节点是长连接还是短链接？</h2><p>长连接</p><h2 id="如何判断-Redis-某个节点是否正常工作？"><a href="#如何判断-Redis-某个节点是否正常工作？" class="headerlink" title="如何判断 Redis 某个节点是否正常工作？"></a>如何判断 Redis 某个节点是否正常工作？</h2><p>Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。</p><h2 id="主从复制架构中，过期-key-如何处理？"><a href="#主从复制架构中，过期-key-如何处理？" class="headerlink" title="主从复制架构中，过期 key 如何处理？"></a>主从复制架构中，过期 key 如何处理？</h2><p>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。</p><h2 id="Redis-是同步复制还是异步复制？"><a href="#Redis-是同步复制还是异步复制？" class="headerlink" title="Redis 是同步复制还是异步复制？"></a>Redis 是同步复制还是异步复制？</h2><p>Redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。</p><h2 id="主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><a href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？" class="headerlink" title="主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？"></a>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</h2><ul><li>出现的阶段不一样<ul><li>repl backlog buffer 是在增量复制阶段出现，<strong>一个主节点只分配一个 repl backlog buffer</strong>；</li><li>replication buffer 是在全量复制阶段和增量复制阶段都会出现，<strong>主节点会给每个新连接的从节点，分配一个 replication buffer</strong>；</li></ul></li><li>两个Buffer都有大小限制，当缓冲区满了之后，发生事情不一样<ul><li>当 repl backlog buffer 满了，因为是环形结构，会直接<strong>覆盖起始位置数据</strong>;</li><li>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，<strong>重新开始全量复制</strong>。</li></ul></li></ul><h2 id="为什么会出现主从数据不一致？"><a href="#为什么会出现主从数据不一致？" class="headerlink" title="为什么会出现主从数据不一致？"></a>为什么会出现主从数据不一致？</h2><p>主从数据不一致，就是指客户端从从节点中读取到的值和主节点中的最新值并不一致。之所以会出现主从数据不一致的现象，是<strong>因为主从节点间的命令复制是异步进行的</strong>，所以无法实现强一致性保证。具体来说，在主从节点命令传播阶段，主节点收到新的写命令后，会发送给从节点。但是，主节点并不会等到从节点实际执行完命令后，再把结果返回给客户端，而是主节点自己在本地执行完命令后，就会向客户端返回结果了。如果从节点还没有执行主节点同步过来的命令，主从节点间的数据就不一致了。</p><h2 id="如何应对主从数据不一致？"><a href="#如何应对主从数据不一致？" class="headerlink" title="如何应对主从数据不一致？"></a>如何应对主从数据不一致？</h2><ul><li>尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。</li><li>可以开发一个外部程序来监控主从节点间的复制进度。</li></ul><h2 id="为什么会有哨兵机制？"><a href="#为什么会有哨兵机制？" class="headerlink" title="为什么会有哨兵机制？"></a>为什么会有哨兵机制？</h2><p>在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p><p>哨兵机制主要负责三件事情：<strong>监控、选主、通知</strong></p><h2 id="如何判断主节点真的故障了？"><a href="#如何判断主节点真的故障了？" class="headerlink" title="如何判断主节点真的故障了？"></a>如何判断主节点真的故障了？</h2><p>哨兵会每隔1s给所有主从节点发送PING命令，当主从节点收到PING命令后，会发送响应命令给哨兵，如果主从节点没在规定时间内响应命令，则认为其主观下线，但是对于判断主节点是否故障通常是部署多个哨兵节点，这样会减少误判，当其中一个哨兵认为主节点主观下线时，就会报告给其他哨兵，其他哨兵对该主节点来进行判断是否下线，最后根据总的赞同票数来判断是否客观下线。</p><h2 id="由哪个哨兵进行主从故障转移？"><a href="#由哪个哨兵进行主从故障转移？" class="headerlink" title="由哪个哨兵进行主从故障转移？"></a>由哪个哨兵进行主从故障转移？</h2><p>首先由发现主节点主观下线的哨兵作为候选者，然后发起投票，当只有一个候选者时，它可以把票投给自己或者他人，然后征询其他哨兵的投票，要成功选举为leader，需要满足两个条件</p><ul><li>拿到半数以上的赞成票；</li><li>拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul><p>当有多个候选者时，候选者会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。</p><h2 id="为什么哨兵节点至少要有3个？"><a href="#为什么哨兵节点至少要有3个？" class="headerlink" title="为什么哨兵节点至少要有3个？"></a>为什么哨兵节点至少要有3个？</h2><p>如果要是2个哨兵，其中一个哨兵要成为leader，必须获得2票，如果一个哨兵挂掉，则无法完成主从切换。</p><h2 id="主从故障转移的过程是怎样的？"><a href="#主从故障转移的过程是怎样的？" class="headerlink" title="主从故障转移的过程是怎样的？"></a>主从故障转移的过程是怎样的？</h2><ul><li>在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点<ul><li>过滤掉已经离线的从节点；</li><li>过滤掉历史网络连接状态不好的从节点；</li><li>将剩下的从节点，进行三轮考察：优先级（越小越靠前）、复制进度（越大越靠前）、ID 号（选择小的）。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。</li></ul></li><li>让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li><li>将新主节点的 IP 地址和信息，通过「发布者&#x2F;订阅者机制」通知给客户端；</li><li>继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li></ul><h2 id="数据库和缓存如何保持一致性？"><a href="#数据库和缓存如何保持一致性？" class="headerlink" title="数据库和缓存如何保持一致性？"></a>数据库和缓存如何保持一致性？</h2><ul><li>先更新数据库，再更新缓存</li></ul><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/8febac10b14bed16cb96d1d944cd08da-17201898929203.png" alt="先更新数据库，再更新缓存"></p><p><strong>解决方案</strong></p><ol><li>在更新缓存前先加个<strong>分布式锁</strong>，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li><li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</li></ol><ul><li>先更新缓存，再更新数据库</li></ul><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/454a8228a6549176ad7e0484fba3c92b-17201899143475.png" alt="先更新缓存，再更新数据库"></p><p>以上两种方法都会出现并发请求导致的数据不一致问题！</p><ul><li>先删除缓存，再更新数据库</li></ul><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/cc208c2931b4e889d1a58cb655537767-17201899364547.png" alt="先删除缓存，再更新数据库"></p><ul><li>「先更新数据库 + 再删除缓存」（<strong>Cache Aside 策略</strong>）的方案，是可以保证数据一致性的。</li></ul><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/1cc7401143e79383ead96582ac11b615-17201899485609.png" alt="先更新数据库 + 再删除缓存"></p><p>理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，<strong>但是在实际中，这个问题出现的概率并不高</strong>。<strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。</p><h2 id="如何解决先更新数据库再删除缓存情况下，删除缓存失败导致数据不一致的问题？"><a href="#如何解决先更新数据库再删除缓存情况下，删除缓存失败导致数据不一致的问题？" class="headerlink" title="如何解决先更新数据库再删除缓存情况下，删除缓存失败导致数据不一致的问题？"></a>如何解决先更新数据库再删除缓存情况下，删除缓存失败导致数据不一致的问题？</h2><p><img src="/2024/07/05/Redis%E5%85%AB%E8%82%A1%E6%96%87/2a2ea2854bbc3ae8ae86d7da45fa32ee-172018996851611.png" alt="失败情况"></p><ul><li>重试机制：可以引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。<ul><li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li><li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</li></ul></li><li>订阅 MySQL binlog，再操作缓存：「<strong>先更新数据库，再删缓存</strong>」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除。</li></ul>]]></content>
    
    
    <categories>
      
      <category>八股</category>
      
    </categories>
    
    
    <tags>
      
      <tag>八股</tag>
      
      <tag>Redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
